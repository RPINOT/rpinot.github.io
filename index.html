<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.7.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Rafael Pinot">

  
  
  
    
  
  <meta name="description" content="Postdoctoral researcher in Computer Science">

  
  <link rel="alternate" hreflang="en-us" href="/">

  


  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      
        
      

      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Rafael Pinot">
  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="/">

  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Rafael Pinot">
  <meta property="og:url" content="/">
  <meta property="og:title" content="Rafael Pinot">
  <meta property="og:description" content="Postdoctoral researcher in Computer Science"><meta property="og:image" content="img/map[gravatar:%!s(bool=false) shape:circle]">
  <meta property="twitter:image" content="img/map[gravatar:%!s(bool=false) shape:circle]"><meta property="og:locale" content="en-us">
  
    <meta property="og:updated_time" content="2023-10-09T00:00:00&#43;00:00">
  

  

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "WebSite","url": "/"
}
</script>


  


  


  





  <title>Rafael Pinot</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#navbar-main" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Rafael Pinot</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Rafael Pinot</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications" data-target="#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#courses" data-target="#courses"><span>Courses</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact" data-target="#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      

      
      <li class="nav-item">
        <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
      </li>
      

      

    </ul>

  </div>
</nav>


  









<span class="js-widget-page d-none"></span>




  







  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="about" class="home-section wg-about   "  >
    <div class="container">
      




  










<div class="row">
  <div class="col-12 col-lg-4">
    <div id="profile">

      
      
      <img class="avatar avatar-circle" src="/authors/admin/avatar_hue55f497b7524ef4738690690bd76ee6d_407941_270x270_fill_q90_lanczos_center.jpg" alt="Avatar">
      

      <div class="portrait-title">
        <h2>Rafael Pinot</h2>
        <h3>Postdoctoral researcher in Computer Science</h3>

        
        <h3>
          <a href="https://www.epfl.ch/fr/" target="_blank" rel="noopener">
          <span>École Polytechnique Fédérale de Lausanne</span>
          </a>
        </h3>
        
      </div>

      <ul class="network-icon" aria-hidden="true">
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="/#contact" >
            <i class="fas fa-envelope big-icon"></i>
          </a>
        </li>
        
        
        
        
        
        
        
        
          
        
        <li>
          <a href="https://scholar.google.fr/citations?user=fGF2kFYAAAAJ&amp;hl=fr" target="_blank" rel="noopener">
            <i class="ai ai-google-scholar big-icon"></i>
          </a>
        </li>
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="https://github.com/rpinot" target="_blank" rel="noopener">
            <i class="fab fa-github big-icon"></i>
          </a>
        </li>
        
      </ul>

    </div>
  </div>
  <div class="col-12 col-lg-8">

    
    <h1>Biography</h1>

    <p>I am a junior professor in the department of mathematics at 
<a href="https://sciences.sorbonne-universite.fr/en/research-areas/mathematics" target="_blank" rel="noopener">Sorbonne Université (Paris 6)</a>. I hold a chair on the <em>mathematical foundation of computer and data science</em> within the 
<a href="https://www.lpsm.paris/en/index" target="_blank" rel="noopener">LPSM research unit</a>. My main line of research is in statistical machine learning with a focus on the <em>privacy and robustness of machine learning</em> algorithms. Most of my work has a theoretical flavor, but I also like to participate in more applied projects to get deeper understanding of state-of-the-art methods, or simply to better grasp the gap that can exist between the theoretical analysis and the empirical performance of some machine learning algorithms.</p>
<p>From 2021 to 2023, I was a postdoctoral researcher at 
<a href="https://www.epfl.ch/fr/" target="_blank" rel="noopener">École
Polytechnique Fédérale de Lausanne</a>, where I worked with <em>Pr. Rachid Guerraoui</em> and Pr. <em>Anne-Marie Kermarrec</em> within the 
<a href="https://ecocloud.ch/" target="_blank" rel="noopener">Ecocloud Research Center</a>. From 2017 to 2020 I completed my PhD in Computer Science at 
<a href="https://www.psl.eu/universite/nos-etablissements/luniversite-psl/universite-paris-dauphine" target="_blank" rel="noopener">Université  Paris Dauphine-PSL</a> and 
<a href="http://www-list.cea.fr/" target="_blank" rel="noopener">CEA LIST institute, Université Paris Saclay</a> where I was advised by <em>Pr. Jamal Atif</em>, <em>Dr. Florian Yger</em>, and <em>Dr. Cédric Gouy-Pailler</em>.</p>


    <div class="row">

      
      <div class="col-md-5">
        <h3>Interests</h3>
        <ul class="ul-interests">
          
          <li>Robustness in Machine Learning</li>
          
          <li>Privacy Preserving Data Analysis</li>
          
          <li>Distributed Machine Learning</li>
          
          <li>Theory of Deep Learning</li>
          
          <li>Graph Theory</li>
          
        </ul>
      </div>
      

      
      <div class="col-md-7">
        <h3>Education</h3>
        <ul class="ul-edu fa-ul">
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">PhD in Computer Science, 2020</p>
              <p class="institution">PSL University (Paris-Dauphine)</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">MSc in Applied Mathematics, 2017</p>
              <p class="institution">Sorbonne Université (Paris 6)</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">BSc in Applied Mathematics, 2016</p>
              <p class="institution">Sorbonne Université (Paris 1)</p>
            </div>
          </li>
          
        </ul>
      </div>
      

    </div>
  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="theses" class="home-section wg-pages   "  >
    <div class="container">
      








  











  
  













  





  


<div class="row">
  <div class="col-12 col-lg-4 section-heading">
    <h1>Theses</h1>
    
  </div>
  <div class="col-12 col-lg-8">

    <!-- raw HTML omitted -->


    
      
        <div class="pub-list-item" style="margin-bottom: 1rem">
  <i class="far fa-file-alt pub-icon" aria-hidden="true"></i>

  
  

  <span class="article-metadata li-cite-author">
    



  
  <span>Rafael Pinot</span>

  </span>
  (2020).
  <a href="/publication/phd-thesis/">On the impact of randomization on robustness in machine learning</a>.
  PhD Thesis in Computer Science, PSL University (Paris-Dauphine).
  
  <p>








  


















  
  
  
    
  
  
  
  
  
    
    
      
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/publication/pdfs/2020UPSLD038.pdf" >
    
    PhD Thesis
  </a>

  
  
  
    
  
  
  
  
  
    
    
      
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/publication/pdfs/Presentation_Soutenance2020.pdf" >
    
    Slides
  </a>

</p>

  
  
</div>

      
    
      
        <div class="pub-list-item" style="margin-bottom: 1rem">
  <i class="far fa-file-alt pub-icon" aria-hidden="true"></i>

  
  

  <span class="article-metadata li-cite-author">
    



  
  <span>Rafael Pinot</span>

  </span>
  (2017).
  <a href="/publication/master-thesis/">Minimum spanning tree release under differential privacy constraints</a>.
  Master Thesis in Statistics, Sorbonne Université (Paris 6).
  
  <p>








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/1801.06423.pdf" target="_blank" rel="noopener">
    
    Master Thesis
  </a>

</p>

  
  
</div>

      
    

    

  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="publications" class="home-section wg-pages   "  >
    <div class="container">
      








  























  





  


<div class="row">
  <div class="col-12 col-lg-4 section-heading">
    <h1>Some Recent Publications</h1>
    
  </div>
  <div class="col-12 col-lg-8">

    

    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span>Rachid Guerraoui</span>, <span>Anne-Marie Kermarrec</span>, <span>Anastasiia Kucherenko</span>, <span>Rafael Pinot</span>, <span>Sasha Voitovych</span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    October 2023
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>DISC 2023</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/disc2023/">On the Inherent Anonymity of Gossiping</a>
  </h3>

  
  <div class="article-style">
    <p>The notion of adversary is a staple of distributed computing. An adversary typically models hostile assumptions about the underlying distributed environment, e.g., a network that can drop messages, an operating system that can delay processes or an attacker that can hack machines. So far, the goal of distributed computing researchers has mainly been to develop a distributed algorithm that can face a given adversary, the abstraction characterizing worst-case scenarios. This paper initiates the study of the somehow opposite approach. Given a distributed algorithm, the adversary is the abstraction we seek to implement. More specifically, we consider the problem of controlling the spread of messages in a large- scale system, conveying the practical motivation of limiting the dissemination of fake news or viruses. Essentially, we assume a general class of gossip protocols, called all-to-all gossip protocols, and devise a practical method to hinder the dissemination. We present the Universal Gossip Fighter (UGF). Just like classical adversaries in distributed computing, UGF can observe the status of a dissemination and decide to stop some processes or delay some messages. The originality of UGF lies in the fact that it is universal, i.e., it applies to any all-to-all gossip protocol. We show that any gossip protocol attacked by UGF ends up exhibiting a quadratic message complexity (in the total number of processes) if it achieves sublinear time of dissemination. We also show that if a gossip protocol aims to achieve a message complexity α times smaller than quadratic, then the time complexity rises exponentially in relation to α. We convey the practical relevance of our theoretical findings by implementing UGF and conducting a set of empirical experiments that confirm some of our results.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2308.02477" target="_blank" rel="noopener">
    
    Conference Paper
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.disc-conference.org/wp/disc2023/" target="_blank" rel="noopener">
    
    DISC 2023
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span>Youssef Allouah</span>, <span>Rachid Guerraoui</span>, <span>Nirupam Gupta</span>, <span>Rafael Pinot</span>, <span>John Stephan</span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    July 2023
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>ICML 2023</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/icml2023_1/">On the Privacy-Robustness-Utility Trilemma in Distributed Learning</a>
  </h3>

  
  <div class="article-style">
    <p>The ubiquity of distributed machine learning (ML) in sensitive public domain applications calls for algorithms that protect data privacy, while being robust to faults and adversarial behaviors. Although privacy and robustness have been extensively studied independently in distributed ML, their synthesis remains poorly understood. We present the first tight analysis of the error incurred by any algorithm ensuring robustness against a fraction of adversarial machines, as well as differential privacy (DP) for honest machines&rsquo; data against any other curious entity. Our analysis exhibits a fundamental trade-off between privacy, robustness, and utility. To prove our lower bound, we consider the case of mean estimation, subject to distributed DP and robustness constraints, and devise reductions to centralized estimation of one-way marginals. We prove our matching upper bound by presenting a new distributed ML algorithm using a high-dimensional robust aggregation rule. The latter amortizes the dependence on the dimension in the error (caused by adversarial workers and DP), while being agnostic to the statistical properties of the data.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2302.04787.pdf" target="_blank" rel="noopener">
    
    Conference Paper
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://icml.cc/Conferences/2023" target="_blank" rel="noopener">
    
    ICML 2023
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span>Sadegh Farhadkhani</span>, <span>Rachid Guerraoui</span>, <span>Nirupam Gupta</span>, <span>Lê Nguyên Hoang</span>, <span>Rafael Pinot</span>, <span>John Stephan</span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    July 2023
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>ICML 2023</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/icml2023_2/">Robust Collaborative Learning with Linear Gradient Overhead</a>
  </h3>

  
  <div class="article-style">
    <p>Collaborative learning algorithms, such as distributed SGD (or D-SGD), are prone to faulty machines that may deviate from their prescribed algorithm because of software or hardware bugs, poisoned data or malicious behaviors. While many solutions have been proposed to enhance the robustness of D-SGD to such machines, previous works either resort to strong assumptions (trusted server, homogeneous data, specific noise model) or impose a gradient computational cost that is several orders of magnitude higher than that of D-SGD. We present MoNNA, a new algorithm that (a) is provably robust under standard assumptions and (b) has a gradient computation overhead that is linear in the fraction of faulty machines, which is conjectured to be tight. Essentially, MoNNA uses Polyak&rsquo;s momentum of local gradients for local updates and nearest-neighbor averaging (NNA) for global mixing, respectively. While MoNNA is rather simple to implement, its analysis has been more challenging and relies on two key elements that may be of independent interest. Specifically, we introduce the mixing criterion of (alpha, lambda)-reduction to analyze the non-linear mixing of non-faulty machines, and present a way to control the tension between the momentum and the model drifts. We validate our theory by experiments on image classification and make our code available at <a href="https://github.com/LPD-EPFL/robust-collaborative-learning">https://github.com/LPD-EPFL/robust-collaborative-learning</a>.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2209.10931.pdf" target="_blank" rel="noopener">
    
    Conference Paper
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://icml.cc/Conferences/2023" target="_blank" rel="noopener">
    
    ICML 2023
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span>Youssef Allouah</span>, <span>Sadegh Farhadkhani</span>, <span>Rachid Guerraoui</span>, <span>Nirupam Gupta</span>, <span>Rafael Pinot</span>, <span>John Stephan</span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    April 2023
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>AISTATS 2023</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/aistats2023/">Fixing by Mixing: A Recipe for Optimal Byzantine ML under Heterogeneity</a>
  </h3>

  
  <div class="article-style">
    <p>Byzantine machine learning (ML) aims to ensure the resilience of distributed learning algorithms to misbehaving (or Byzantine) machines. Although this problem received significant attention, prior works often assume the data held by the machines to be homogeneous, which is seldom true in practical settings. Data heterogeneity makes Byzantine ML considerably more challenging, since a Byzantine machine can hardly be distinguished from a non-Byzantine outlier. A few solutions have been proposed to tackle this issue, but these provide suboptimal probabilistic guarantees and fare poorly in practice. This paper closes the theoretical gap, achieving optimality and inducing good empirical results. In fact, we show how to automatically adapt existing solutions for (homogeneous) Byzantine ML to the heterogeneous setting through a powerful mechanism, we call nearest neighbor mixing (NNM), which boosts any standard robust distributed gradient descent variant to yield optimal Byzantine resilience under heterogeneity. We obtain similar guarantees (in expectation) by plugging NNM in the distributed stochastic heavy ball method, a practical substitute to distributed gradient descent. We obtain empirical results that significantly outperform state-of-the-art Byzantine ML solutions.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2302.01772.pdf" target="_blank" rel="noopener">
    
    Conference Paper
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://aistats.org/aistats2023/" target="_blank" rel="noopener">
    
    AISTATS 2023
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span>Laurent Meunier</span>, <span>Raphael Ettedgui</span>, <span>Rafael Pinot</span>, <span>Yann Chevaleyre</span>, <span>Jamal Atif</span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    September 2022
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>NeurIPS 2022</em>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/neurips2022/">Towards Consistency in Adversarial Classification</a>
  </h3>

  
  <div class="article-style">
    <p>In this paper, we study the problem of consistency in the context of adversarial examples. Specifically, we tackle the following question; can surrogate losses still be used as a proxy for minimizing the 0/1 loss in the presence of an adversary that alters the inputs at test-time? Different from the standard classification task, this question cannot be reduced to a point-wise minimization problem, and calibration needs not to be sufficient to ensure consistency. In this paper, we expose some pathological behaviors specific to the adversarial problem, and show that no convex surrogate loss can be consistent or calibrated in this context. It is therefore necessary to design another class of surrogate functions that can be used to solve the adversarial consistency issue. As a first step towards designing such a class, we identify sufficient and necessary conditions for a surrogate loss to be calibrated in both the adversarial and standard settings. Finally, we give some directions for building a class of losses that could be consistent in the adversarial framework.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2205.10022.pdf" target="_blank" rel="noopener">
    
    Conference Paper
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://nips.cc/Conferences/2022" target="_blank" rel="noopener">
    
    Neurips 2022 (Spotlight)
  </a>


  </div>
  

</div>

      
    

    
    <div class="see-all">
      <a href="/publication/">
        See all publications
        <i class="fas fa-angle-right"></i>
      </a>
    </div>
    

  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="courses" class="home-section wg-blank   "  >
    <div class="container">
      


<div class="row">
  
    <div class="col-12 col-lg-4 section-heading">
      <h1>Teaching</h1>
      
    </div>
    <div class="col-12 col-lg-8">
      <h3 id="université-paris-dauphine-pslhttpwwwdauphinefr"><strong>
<a href="http://www.dauphine.fr/" target="_blank" rel="noopener">Université Paris Dauphine PSL</a></strong></h3>
<ul>
<li>
<p>Lecturer in Trustworthy Machine Learning - MBa C.S (2019-2020)</p>
</li>
<li>
<p>Lecturer in Mathematics for Machine Learning - MSc C.S (2019-2020)</p>
</li>
<li>
<p>Teaching assistant in Introduction to Machine Learning - MSc C.S (2017-2020)</p>
</li>
<li>
<p>Teaching assistant in Introduction to Machine Learning - MBa B.I (2017-2020)</p>
</li>
</ul>
<h3 id="sorbonne-université-paris-1httpswwwuniv-paris1fr"><strong>
<a href="https://www.univ-paris1.fr/" target="_blank" rel="noopener">Sorbonne Université (Paris 1)</a></strong></h3>
<ul>
<li>Teaching assistant in Calculus - BSc Mathematics (2017-2018)</li>
</ul>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="contact" class="home-section wg-contact   "  >
    <div class="container">
      





<div class="row contact-widget">
  <div class="col-12 col-lg-4 section-heading">
    <h1>Contact</h1>
    
  </div>
  <div class="col-12 col-lg-8">
    <h3 id="contact-at-sorbonne-université"><strong>Contact at Sorbonne Université</strong></h3>
<ul>
<li><strong>E-Mail address:</strong>  {lastname}[at]lpsm.paris</li>
</ul>
<h3 id="contact-at-epfl-may-be-deprecated"><strong>Contact at EPFL (may be deprecated)</strong></h3>
<ul>
<li><strong>E-Mail address:</strong>  {firstname}.{lastname}[at]epfl.ch</li>
</ul>


    

    <ul class="fa-ul">

      

      

      
      

      

      

      

      
      

    </ul>

    

  </div>
</div>

    </div>
  </section>



      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
        
      

    

    
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    

    
    

    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
    
    
    
    <script src="/js/academic.min.c97b94000ee75a76d9bc08f5a2e44814.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    Rafael Pinot &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
