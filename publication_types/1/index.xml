<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>1 | Rafael Pinot</title>
    <link>/publication_types/1/</link>
      <atom:link href="/publication_types/1/index.xml" rel="self" type="application/rss+xml" />
    <description>1</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Rafael Pinot</copyright><lastBuildDate>Mon, 09 Oct 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>1</title>
      <link>/publication_types/1/</link>
    </image>
    
    <item>
      <title>On the Inherent Anonymity of Gossiping</title>
      <link>/publication/disc2023/</link>
      <pubDate>Mon, 09 Oct 2023 00:00:00 +0000</pubDate>
      <guid>/publication/disc2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>On the Privacy-Robustness-Utility Trilemma in Distributed Learning</title>
      <link>/publication/icml2023_1/</link>
      <pubDate>Sun, 23 Jul 2023 00:00:00 +0000</pubDate>
      <guid>/publication/icml2023_1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Robust Collaborative Learning with Linear Gradient Overhead</title>
      <link>/publication/icml2023_2/</link>
      <pubDate>Sun, 23 Jul 2023 00:00:00 +0000</pubDate>
      <guid>/publication/icml2023_2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Fixing by Mixing: A Recipe for Optimal Byzantine ML under Heterogeneity</title>
      <link>/publication/aistats2023/</link>
      <pubDate>Tue, 11 Apr 2023 00:00:00 +0000</pubDate>
      <guid>/publication/aistats2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Towards Consistency in Adversarial Classification</title>
      <link>/publication/neurips2022/</link>
      <pubDate>Thu, 08 Sep 2022 00:00:00 +0000</pubDate>
      <guid>/publication/neurips2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Byzantine Machine Learning Made Easy by Resilent Averaging of Momentums</title>
      <link>/publication/icml2022/</link>
      <pubDate>Sun, 17 Jul 2022 00:00:00 +0000</pubDate>
      <guid>/publication/icml2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Universal Gossip Fighter</title>
      <link>/publication/ipdps2022/</link>
      <pubDate>Mon, 30 May 2022 00:00:00 +0000</pubDate>
      <guid>/publication/ipdps2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Differential Privacy and Byzantine Resilience in SGD: Do They Add Up?</title>
      <link>/publication/podc2021/</link>
      <pubDate>Mon, 26 Jul 2021 00:00:00 +0000</pubDate>
      <guid>/publication/podc2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Mixed Nash Equilibria in the Adversarial Examples Game</title>
      <link>/publication/icml2021/</link>
      <pubDate>Sun, 18 Jul 2021 00:00:00 +0000</pubDate>
      <guid>/publication/icml2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SPEED: Secure, PrivatE,and Efficient Deep learning</title>
      <link>/publication/ecml2021/</link>
      <pubDate>Wed, 24 Mar 2021 00:00:00 +0000</pubDate>
      <guid>/publication/ecml2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Advocating for Multiple Defense Strategies against Adversarial Examples</title>
      <link>/publication/ecml2020/</link>
      <pubDate>Mon, 14 Sep 2020 00:00:00 +0000</pubDate>
      <guid>/publication/ecml2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Randomization matters. How to defend against strong adversarial attacks</title>
      <link>/publication/randomizationmatters/</link>
      <pubDate>Mon, 24 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/publication/randomizationmatters/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Theoretical evidence for adversarial robustness through randomization</title>
      <link>/publication/neurips2019/</link>
      <pubDate>Sun, 08 Dec 2019 00:00:00 +0000</pubDate>
      <guid>/publication/neurips2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A unified view on differential privacy and robustness to adversarial examples</title>
      <link>/publication/ecml2019/</link>
      <pubDate>Fri, 20 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/publication/ecml2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Graph-based Clustering under Differential Privacy</title>
      <link>/publication/uai2018/</link>
      <pubDate>Sun, 05 Aug 2018 00:00:00 +0000</pubDate>
      <guid>/publication/uai2018/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
